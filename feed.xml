<feed xmlns="http://www.w3.org/2005/Atom"> <id>https://codetudau.com/</id><title>thanhtt</title><subtitle>Data Engineer, Bloger</subtitle> <updated>2021-04-04T16:10:07+07:00</updated> <author> <name>thanhtt</name> <uri>https://codetudau.com/</uri> </author><link rel="self" type="application/atom+xml" href="https://codetudau.com/feed.xml"/><link rel="alternate" type="text/html" hreflang="vi" href="https://codetudau.com/"/> <generator uri="https://jekyllrb.com/" version="4.2.0">Jekyll</generator> <rights> © 2021 thanhtt </rights> <icon>/assets/img/favicons/favicon.ico</icon> <logo>/assets/img/favicons/favicon-96x96.png</logo> <entry><title>Cài đặt hệ thống gợi ý bài viết Made in Vietnam và FREE</title><link href="https://codetudau.com/posts/de-xuat-bai-viet-lien-quan/" rel="alternate" type="text/html" title="Cài đặt hệ thống gợi ý bài viết Made in Vietnam và FREE" /><published>2021-03-28T15:33:00+07:00</published> <updated>2021-03-28T15:33:00+07:00</updated> <id>https://codetudau.com/posts/de-xuat-bai-viet-lien-quan/</id> <content src="https://codetudau.com/posts/de-xuat-bai-viet-lien-quan/" /> <author> <name>thanhtt</name> </author> <category term="blog" /> <category term="recommender system" /> <summary> Lâu lắm mới có dịp viết blog, dạo này AE khoẻ không :) Hiện tại mình làm việc tại một công ty nho nhỏ. Ở công ty này có phong trào viết blog để anh chị em trong công ty chia sẻ được những gì mình đang tìm hiểu, nghiên cứu. Hơn nữa bài viết nào nhiều pageview nhất sẽ được thưởng 500k. Lúc đầu anh chị em hào hứng lắm. Tuy nhiên gần đây AE không hứng thú viết blog nữa, dẫn đến phong trào đi xuốn... </summary> </entry> <entry><title>Cải thiện phương pháp Count Base với Pointwise Mutual Information</title><link href="https://codetudau.com/posts/cai-thien-count-base/" rel="alternate" type="text/html" title="Cải thiện phương pháp Count Base với Pointwise Mutual Information" /><published>2021-03-09T18:33:00+07:00</published> <updated>2021-03-10T17:17:44+07:00</updated> <id>https://codetudau.com/posts/cai-thien-count-base/</id> <content src="https://codetudau.com/posts/cai-thien-count-base/" /> <author> <name>thanhtt</name> </author> <category term="blog" /> <category term="python" /> <category term="NLP" /> <summary> Ở bài viết trước mình đã giới thiệu với các bạn một phương pháp vector hoá từ có tên là Count Base. Dựa vào việc tạo ra một co-occurence matrix của từ, chắc hẳn bạn đã tạo được vector của từ rồi nhỉ. Tuy nhiên co-occurence matrix đó vẫn còn những chỗ cần cải thiện để có thể áp dụng được với thực tế. Pointwise Mutual Information Ở bài viết trước, các bạn có thể thấy là mỗi phần tử của co-occur... </summary> </entry> <entry><title>Word To Vector với phương pháp Count Base</title><link href="https://codetudau.com/posts/word-to-vector-voi-phuong-phap-count-base/" rel="alternate" type="text/html" title="Word To Vector với phương pháp Count Base" /><published>2021-03-09T15:33:00+07:00</published> <updated>2021-03-09T15:33:00+07:00</updated> <id>https://codetudau.com/posts/word-to-vector-voi-phuong-phap-count-base/</id> <content src="https://codetudau.com/posts/word-to-vector-voi-phuong-phap-count-base/" /> <author> <name>thanhtt</name> </author> <category term="blog" /> <category term="python" /> <category term="deep-learning" /> <summary> Đi cùng với lịch sử phát triển của xử lý ngôn ngữ tự nhiên, đã có rất nhiều nghiên cứu về việc vector hoá từ. Nhìn vào các nghiên cứu đó có thể thấy hầu hết các phương pháp dựa trên một idea cơ bản đó chính là: Ý nghĩa của 1 từ được tạo thành từ các từ xung quanh. Giới khoa học gọi ngắn gọn là distributional hypothesis, và dựa vào idea này, rất nhiều nghiên cứu về việc vector hoá từ được d... </summary> </entry> <entry><title>Neural Network và Deep Learning là gì ?</title><link href="https://codetudau.com/posts/neural-network-va-deep-learning-la-gi/" rel="alternate" type="text/html" title="Neural Network và Deep Learning là gì ?" /><published>2021-03-09T15:33:00+07:00</published> <updated>2021-03-09T15:33:00+07:00</updated> <id>https://codetudau.com/posts/neural-network-va-deep-learning-la-gi/</id> <content src="https://codetudau.com/posts/neural-network-va-deep-learning-la-gi/" /> <author> <name>thanhtt</name> </author> <category term="blog" /> <category term="python" /> <category term="deep-learning" /> <summary> Chào các bạn, hôm nay đẹp trời lại có thời gian rảnh mình sẽ viết tiếp chuỗi bài về Deep Learning. Như bài trước mình đã giới thiệu với các bạn về Perceptron, nếu bạn chưa biết thì bạn có thể xem lại tại đây. Và bài này mình sẽ giới thiệu về Neural Network(NN) và NN có mối liên hệ như thế nào với Deep Learning. Mục tiêu chính của bài viết: Hiểu được Neuron Network là gì Deep Learning là g... </summary> </entry> <entry><title>Đi tìm cội nguồn của Deep Learning - Perceptron</title><link href="https://codetudau.com/posts/deeplearning-perceptron-la-gi/" rel="alternate" type="text/html" title="Đi tìm cội nguồn của Deep Learning - Perceptron" /><published>2021-03-09T13:33:00+07:00</published> <updated>2021-03-09T13:33:00+07:00</updated> <id>https://codetudau.com/posts/deeplearning-perceptron-la-gi/</id> <content src="https://codetudau.com/posts/deeplearning-perceptron-la-gi/" /> <author> <name>thanhtt</name> </author> <category term="blog" /> <category term="python" /> <summary> Hẳn là ai cũng biết sông bắt nguồn từ suối, các hồ nước từ độ cao lớn hơn. Và chắc hẳn nhiều người đã biết đến DeepLearning hoặc đã, đang làm việc với DeepLearning tuy nhiên bạn có biết nguồn gốc của DeepLearning(Neural Network)　từ đâu mà có không? Đó chính là Perceptron algorithm, bài viết này mình sẽ giải thích cặn kẽ với các bạn Perceptron là gì? Tại sao nó lại là cội nguồn của DeepLearning... </summary> </entry> </feed>

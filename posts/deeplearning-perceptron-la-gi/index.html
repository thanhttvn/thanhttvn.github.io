<!DOCTYPE html><html lang="vi" ><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><meta name="pv-cache-enabled" content="false"><meta name="generator" content="Jekyll v4.2.0" /><meta property="og:title" content="Đi tìm cội nguồn của Deep Learning - Perceptron" /><meta name="author" content="thanhtt" /><meta property="og:locale" content="vi" /><meta name="description" content="Hẳn là ai cũng biết sông bắt nguồn từ suối, các hồ nước từ độ cao lớn hơn. Và chắc hẳn nhiều người đã biết đến DeepLearning hoặc đã, đang làm việc với DeepLearning tuy nhiên bạn có biết nguồn gốc của DeepLearning(Neural Network)　từ đâu mà có không?" /><meta property="og:description" content="Hẳn là ai cũng biết sông bắt nguồn từ suối, các hồ nước từ độ cao lớn hơn. Và chắc hẳn nhiều người đã biết đến DeepLearning hoặc đã, đang làm việc với DeepLearning tuy nhiên bạn có biết nguồn gốc của DeepLearning(Neural Network)　từ đâu mà có không?" /><link rel="canonical" href="https://codetudau.com/posts/deeplearning-perceptron-la-gi/" /><meta property="og:url" content="https://codetudau.com/posts/deeplearning-perceptron-la-gi/" /><meta property="og:site_name" content="thanhtt" /><meta property="og:type" content="article" /><meta property="article:published_time" content="2021-03-09T13:33:00+07:00" /><meta name="twitter:card" content="summary" /><meta property="twitter:title" content="Đi tìm cội nguồn của Deep Learning - Perceptron" /><meta name="twitter:site" content="@twitter_username" /><meta name="twitter:creator" content="@thanhtt" /><meta name="google-site-verification" content="google_meta_tag_verification" /> <script type="application/ld+json"> {"headline":"Đi tìm cội nguồn của Deep Learning - Perceptron","dateModified":"2021-03-09T13:33:00+07:00","datePublished":"2021-03-09T13:33:00+07:00","description":"Hẳn là ai cũng biết sông bắt nguồn từ suối, các hồ nước từ độ cao lớn hơn. Và chắc hẳn nhiều người đã biết đến DeepLearning hoặc đã, đang làm việc với DeepLearning tuy nhiên bạn có biết nguồn gốc của DeepLearning(Neural Network)　từ đâu mà có không?","url":"https://codetudau.com/posts/deeplearning-perceptron-la-gi/","mainEntityOfPage":{"@type":"WebPage","@id":"https://codetudau.com/posts/deeplearning-perceptron-la-gi/"},"@type":"BlogPosting","author":{"@type":"Person","name":"thanhtt"},"@context":"https://schema.org"}</script><title>Đi tìm cội nguồn của Deep Learning - Perceptron | thanhtt</title><link rel="shortcut icon" href="/assets/img/favicons/favicon.ico" type="image/x-icon"><link rel="icon" href="/assets/img/favicons/favicon.ico" type="image/x-icon"><link rel="apple-touch-icon" href="/assets/img/favicons/apple-icon.png"><link rel="apple-touch-icon" href="/assets/img/favicons/apple-icon-precomposed.png"><link rel="apple-touch-icon" sizes="57x57" href="/assets/img/favicons/apple-icon-57x57.png"><link rel="apple-touch-icon" sizes="60x60" href="/assets/img/favicons/apple-icon-60x60.png"><link rel="apple-touch-icon" sizes="72x72" href="/assets/img/favicons/apple-icon-72x72.png"><link rel="apple-touch-icon" sizes="76x76" href="/assets/img/favicons/apple-icon-76x76.png"><link rel="apple-touch-icon" sizes="114x114" href="/assets/img/favicons/apple-icon-114x114.png"><link rel="apple-touch-icon" sizes="120x120" href="/assets/img/favicons/apple-icon-120x120.png"><link rel="apple-touch-icon" sizes="144x144" href="/assets/img/favicons/apple-icon-144x144.png"><link rel="apple-touch-icon" sizes="152x152" href="/assets/img/favicons/apple-icon-152x152.png"><link rel="apple-touch-icon" sizes="180x180" href="/assets/img/favicons/apple-icon-180x180.png"><link rel="icon" type="image/png" sizes="192x192" href="/assets/img/favicons/android-icon-192x192.png"><link rel="icon" type="image/png" sizes="32x32" href="/assets/img/favicons/favicon-32x32.png"><link rel="icon" type="image/png" sizes="96x96" href="/assets/img/favicons/favicon-96x96.png"><link rel="icon" type="image/png" sizes="16x16" href="/assets/img/favicons/favicon-16x16.png"><link rel="manifest" href="/assets/img/favicons/manifest.json"><meta name='msapplication-config' content='/assets/img/favicons/browserconfig.xml'><meta name="msapplication-TileColor" content="#ffffff"><meta name="msapplication-TileImage" content="/assets/img/favicons/ms-icon-144x144.png"><meta name="theme-color" content="#ffffff"><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin="anonymous"><link rel="dns-prefetch" href="https://fonts.gstatic.com"><link rel="preconnect" href="https://www.google-analytics.com" crossorigin="use-credentials"><link rel="dns-prefetch" href="https://www.google-analytics.com"><link rel="preconnect" href="https://www.googletagmanager.com" crossorigin="anonymous"><link rel="dns-prefetch" href="https://www.googletagmanager.com"><link rel="preconnect" href="cdn.jsdelivr.net"><link rel="dns-prefetch" href="cdn.jsdelivr.net"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.0.0/dist/css/bootstrap.min.css" integrity="sha256-LA89z+k9fjgMKQ/kq4OO2Mrf8VltYml/VES+Rg0fh20=" crossorigin="anonymous"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.11.2/css/all.min.css" integrity="sha256-+N4/V/SbAFiW1MPBCXnfnP9QSN3+Keu+NlB+0ev/YKQ=" crossorigin="anonymous"><link rel="stylesheet" href="/assets/css/style.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@1.0.1/dist/bootstrap-toc.min.css"> <script src="https://cdn.jsdelivr.net/npm/jquery@3/dist/jquery.min.js"></script> <script defer src="https://cdn.jsdelivr.net/combine/npm/popper.js@1.15.0,npm/bootstrap@4/dist/js/bootstrap.min.js"></script> <script defer src="/assets/js/dist/post.min.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script defer src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script> <script defer src="/app.js"></script> <script defer src="https://www.googletagmanager.com/gtag/js?id="></script> <script> document.addEventListener("DOMContentLoaded", function(event) { window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', ''); }); </script><body data-spy="scroll" data-target="#toc"><div id="sidebar" class="d-flex flex-column align-items-end"><div class="profile-wrapper text-center"><div id="avatar"> <a href="/" alt="avatar" class="mx-auto"> <img src="/assets/img/avatar/ttt-avatar.png" alt="avatar" onerror="this.style.display='none'"> </a></div><div class="site-title mt-3"> <a href="/">thanhtt</a></div><div class="site-subtitle font-italic">thanhtt - Data Engineer</div></div><ul class="w-100"><li class="nav-item"> <a href="/" class="nav-link"> <i class="fa-fw fas fa-home ml-xl-3 mr-xl-3 unloaded"></i> <span>HOME</span> </a><li class="nav-item"> <a href="/categories/" class="nav-link"> <i class="fa-fw fas fa-stream ml-xl-3 mr-xl-3 unloaded"></i> <span>CATEGORIES</span> </a><li class="nav-item"> <a href="/tags/" class="nav-link"> <i class="fa-fw fas fa-tags ml-xl-3 mr-xl-3 unloaded"></i> <span>TAGS</span> </a><li class="nav-item"> <a href="/archives/" class="nav-link"> <i class="fa-fw fas fa-archive ml-xl-3 mr-xl-3 unloaded"></i> <span>ARCHIVES</span> </a><li class="nav-item"> <a href="/about/" class="nav-link"> <i class="fa-fw fas fa-info ml-xl-3 mr-xl-3 unloaded"></i> <span>ABOUT</span> </a></ul><div class="sidebar-bottom mt-auto d-flex flex-wrap justify-content-center"> <a href="https://github.com/thanhttvn" aria-label="github" class="order-3" target="_blank" rel="noopener"> <i class="fab fa-github-alt"></i> </a> <a href="https://twitter.com/twitter_username" aria-label="twitter" class="order-4" target="_blank" rel="noopener"> <i class="fab fa-twitter"></i> </a> <a href=" javascript:location.href = 'mailto:' + ['thanhtt.vn93','gmail.com'].join('@')" aria-label="email" class="order-5" > <i class="fas fa-envelope"></i> </a> <a href="/feed.xml" aria-label="rss" class="order-6" > <i class="fas fa-rss"></i> </a> <span class="icon-border order-2"></span> <span id="mode-toggle-wrapper" class="order-1"> <i class="mode-toggle fas fa-adjust"></i> <script type="text/javascript"> class ModeToggle { static get MODE_KEY() { return "mode"; } static get DARK_MODE() { return "dark"; } static get LIGHT_MODE() { return "light"; } constructor() { if (this.hasMode) { if (this.isDarkMode) { if (!this.isSysDarkPrefer) { this.setDark(); } } else { if (this.isSysDarkPrefer) { this.setLight(); } } } var self = this; /* always follow the system prefers */ this.sysDarkPrefers.addListener(function() { if (self.hasMode) { if (self.isDarkMode) { if (!self.isSysDarkPrefer) { self.setDark(); } } else { if (self.isSysDarkPrefer) { self.setLight(); } } self.clearMode(); } self.updateMermaid(); }); } /* constructor() */ setDark() { $('html').attr(ModeToggle.MODE_KEY, ModeToggle.DARK_MODE); sessionStorage.setItem(ModeToggle.MODE_KEY, ModeToggle.DARK_MODE); } setLight() { $('html').attr(ModeToggle.MODE_KEY, ModeToggle.LIGHT_MODE); sessionStorage.setItem(ModeToggle.MODE_KEY, ModeToggle.LIGHT_MODE); } clearMode() { $('html').removeAttr(ModeToggle.MODE_KEY); sessionStorage.removeItem(ModeToggle.MODE_KEY); } get sysDarkPrefers() { return window.matchMedia("(prefers-color-scheme: dark)"); } get isSysDarkPrefer() { return this.sysDarkPrefers.matches; } get isDarkMode() { return this.mode == ModeToggle.DARK_MODE; } get isLightMode() { return this.mode == ModeToggle.LIGHT_MODE; } get hasMode() { return this.mode != null; } get mode() { return sessionStorage.getItem(ModeToggle.MODE_KEY); } /* get the current mode on screen */ get modeStatus() { if (this.isDarkMode || (!this.hasMode && this.isSysDarkPrefer) ) { return ModeToggle.DARK_MODE; } else { return ModeToggle.LIGHT_MODE; } } updateMermaid() { if (typeof mermaid !== "undefined") { let expectedTheme = (this.modeStatus === ModeToggle.DARK_MODE? "dark" : "default"); let config = { theme: expectedTheme }; /* re-render the SVG › <https://github.com/mermaid-js/mermaid/issues/311#issuecomment-332557344> */ $(".mermaid").each(function() { let svgCode = $(this).prev().children().html(); $(this).removeAttr("data-processed"); $(this).html(svgCode); }); mermaid.initialize(config); mermaid.init(undefined, ".mermaid"); } } flipMode() { if (this.hasMode) { if (this.isSysDarkPrefer) { if (this.isLightMode) { this.clearMode(); } else { this.setLight(); } } else { if (this.isDarkMode) { this.clearMode(); } else { this.setDark(); } } } else { if (this.isSysDarkPrefer) { this.setLight(); } else { this.setDark(); } } this.updateMermaid(); } /* flipMode() */ } /* ModeToggle */ let toggle = new ModeToggle(); $(".mode-toggle").click(function() { toggle.flipMode(); }); </script> </span></div></div><div id="topbar-wrapper" class="row justify-content-center topbar-down"><div id="topbar" class="col-11 d-flex h-100 align-items-center justify-content-between"> <span id="breadcrumb"> <span> <a href="/"> Posts </a> </span> <span>Đi tìm cội nguồn của Deep Learning - Perceptron</span> </span> <i id="sidebar-trigger" class="fas fa-bars fa-fw"></i><div id="topbar-title"> Post</div><i id="search-trigger" class="fas fa-search fa-fw"></i> <span id="search-wrapper" class="align-items-center"> <i class="fas fa-search fa-fw"></i> <input class="form-control" id="search-input" type="search" aria-label="search" placeholder="Search..."> <i class="fa fa-times-circle fa-fw" id="search-cleaner"></i> </span> <span id="search-cancel" >Cancel</span></div></div><div id="main-wrapper"><div id="main"><div class="row"><div id="post-wrapper" class="col-12 col-lg-11 col-xl-8"><div class="post pl-1 pr-1 pl-sm-2 pr-sm-2 pl-md-4 pr-md-4"><h1 data-toc-skip>Đi tìm cội nguồn của Deep Learning - Perceptron</h1><div class="post-meta text-muted d-flex flex-column"><div> <span class="semi-bold"> thanhtt </span> <span class="timeago " data-toggle="tooltip" data-placement="bottom" title="Tue, Mar 9, 2021, 1:33 PM +0700" prep="on" > Mar 9 <i class="unloaded">2021-03-09T13:33:00+07:00</i> </span></div><div> <span class="readtime" data-toggle="tooltip" data-placement="bottom" title="1230 words">6 min</span></div></div><div class="post-content"> <img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="/assets/img/posts/2018/04/perceptron-deeplearning.png" class="preview-img" alt="Preview Image"><p>Hẳn là ai cũng biết sông bắt nguồn từ suối, các hồ nước từ độ cao lớn hơn. Và chắc hẳn nhiều người đã biết đến DeepLearning hoặc đã, đang làm việc với DeepLearning tuy nhiên bạn có biết nguồn gốc của DeepLearning(Neural Network)　từ đâu mà có không?</p><p>Đó chính là Perceptron algorithm, bài viết này mình sẽ giải thích cặn kẽ với các bạn Perceptron là gì? Tại sao nó lại là cội nguồn của DeepLearning.</p><p>Đối tượng bài viết:</p><ul><li>Nếu bạn muốn tìm hiểu DeepLearning mà chưa biết bắt đầu từ đâu.<li>Nếu bạn đang làm việc với DeepLearning nhưng lại chưa nắm được kiến thức cơ bản.</ul><h1 id="perceptron-là-gì">Perceptron là gì?</h1><p>Perceptron sẽ nhận input đầu vào là nhiều tín hiệu khác nhau, output là 1 tín hiệu duy nhất. “Tín hiệu” ở đây bạn có thể tưởng tượng như một vật nào đó có dòng chảy như dòng điện hay sông chẳng hạn. Dòng điện thì sẽ được truyền đi theo đường dây, việc dòng điện được truyền đi có bản chất là dòng dịch chuyển các electron dựa trên sự chênh lệch hiệu điện thế. Khác với dòng điện, tín hiệu của Perceptron mang 2 giá trị “1/0”, 1 mang ý nghĩa là truyền tín hiệu, 0 là không truyền tín hiệu.</p><p>Như ví dụ dưới đây biểu diễn 1 Perceptron nhận 2 tín hiệu đầu vào.</p><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="/assets/img/posts/2018/04/Perceptron-1.png" alt="Perceptron-1" /></p><ul><li>x1, x2 là tín hiệu input<li>y là tín hiệu output<li>w1, w2 là weight<li>○ có thể gọi là node hoặc neuron</ul><p>Bạn có đang thắc mắc weight là cái khỉ gì không ? Hiểu đơn giản giống như dòng điện, weight chính là trở kháng. Trở kháng càng cao thì dòng điện càng khó được truyền đi phải không. Tuy nhiên weight của Perceptron thì ngược lại, giá trị càng cao thì tín hiệu càng dễ được truyền đi.</p><p>Khi tín hiệu x được gửi đến neuron thì tại mỗi neuron sẽ nhân với weight $ ( x_1 \omega _1, x_2 \omega _2) $. Output sẽ được tính đơn giản như sau:</p><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="/assets/img/posts/2018/04/----------2018-04-15-11.02.43.png" alt="----------2018-04-15-11.02.43" /></p><p>$ \theta $ có tên gọi là ngưỡng (threshold). Chỉ khi nào giá trị vượt ngưỡng thì y mới return về 1. Vì vậy chức năng của Perceptron chính là điều khiển các tín hiệu. Chốt lại là với weight càng lớn thì độ quan trọng của tín hiệu càng cao.</p><h1 id="mạch-logic-đơn-giản">Mạch logic đơn giản</h1><h2 id="mạch-and">Mạch AND</h2><p>Phần trên mình đã trình bày nguyên lý hoạt động của Perceptron, tiếp theo là ứng dụng của nó ra sao. Chắc hẳn bạn cũng biết mạch AND là gì. Đơn giản là mạch AND có 2 input và 1 output, chỉ khi input $ x_1, x_2 $ bằng 1 thì output mới bằng 1.</p><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="/assets/img/posts/2018/04/-and-gate.png" alt="-and-gate" /></p><p>Vậy thì nếu muốn biểu diễn mạch AND bằng Perceptron thì sẽ làm thế nào ? Thực chất công việc cần làm là lựa chọn $ ( \omega _1, \omega _2, \theta ) $ sao cho thỏa mãn như hình. Ví dụ $ ( \omega _1, \omega _2, \theta ) $ = (0.5, 0.5, 0.7). Với parameter này, chỉ khi cả $ x_1, x_2 $ bằng 1 thì tổng mới $ &gt; \theta $ và output y = 1.</p><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="/assets/img/posts/2018/04/AND-perceptron.png" alt="AND-perceptron" /></p><h2 id="mạch-nand-và-or">Mạch NAND và OR</h2><p>NAND có ý nghĩa là Not AND nên output sẽ ngược lại so với AND. Tương tự như trên để biểu diễn mạch NAND bằng Perceptron thì cần lựa chọn parameter $ ( \omega _1, \omega _2, \theta ) $. Ví dụ parameter là $ ( \omega _1, \omega _2, \theta ) = (-0.5, -0.5, -0.7)$</p><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="/assets/img/posts/2018/04/NAND-perceptron-1.png" alt="NAND-perceptron-1" /></p><p>Cũng không có khó khăn gì đúng không các bạn ^^. Với mạch OR thì như sau:</p><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="/assets/img/posts/2018/04/OR-gate.png" alt="OR-gate" /></p><p>Vậy bạn thử suy nghĩ xem nên chọn parameter như thế nào cho phù hợp và để lại comment phía ↓ nhé. ^^</p><p><em>Ở đây, việc chọn parameter cho Perceptron hoàn toàn bằng tay. Công việc của Machinelearning sẽ thay chúng ta lựa chọn parameter cho phù hợp và công việc của chúng ta là code model Perceptron</em></p><p>Ở trên mình đã nói đến 3 mạch cơ bản là AND, NAND, OR. Về bản chất chúng hoàn toàn giống nhau, sự khác nhau chỉ là ở parameter Perceptron $ ( \omega _1, \omega _2, \theta ) $ mà thôi. Chính vì vậy với 1 model duy nhất, bằng việc thay đổi parameter thích hợp thì sẽ transform được mạch AND, NAND hay OR.</p><h2 id="implement-perceptron">Implement Perceptron</h2><h3 id="weight-và-bias">Weight và Bias</h3><p>Biểu diễn lại công thức đầu tiên của Perceptron như sau:</p><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="/assets/img/posts/2018/04/----------2018-04-15-12.33.02.png" alt="----------2018-04-15-12.33.02" /></p><p>b chính là threshold ở công thức trên, và ở đây thay vì gọi như vậy sẽ được gọi là bias, vì threshold bây giờ sẽ là 0. $ \omega _1, \omega _2 $ sẽ là weight. Chức năng của bias và weight đương nhiên là khác nhau. Với chức năng của weight như đã nói ở trên là quyết định độ quan trọng của mỗi input, còn bias có chức năng tương tự như ngưỡng (threshold).</p><p>Chú ý:</p><ul><li>Tùy trường hợp, tài liệu mà $ \omega _1, \omega _2, b $ cùng được gọi là weight.</ul><h3 id="implement-and-với-weight-và-bias">Implement AND với weight và bias.</h3><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
</pre><td class="rouge-code"><pre><span class="c1"># coding: utf-8
</span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>

<span class="k">def</span> <span class="nf">AND</span><span class="p">(</span><span class="n">x1</span><span class="p">,</span> <span class="n">x2</span><span class="p">):</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">([</span><span class="n">x1</span><span class="p">,</span> <span class="n">x2</span><span class="p">])</span><span class="err">　</span> <span class="c1">#input
</span>    <span class="n">w</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">])</span> <span class="c1">#weight
</span>    <span class="n">b</span> <span class="o">=</span> <span class="o">-</span><span class="mf">0.7</span> <span class="c1">#bias
</span>    <span class="n">tmp</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nb">sum</span><span class="p">(</span><span class="n">w</span><span class="o">*</span><span class="n">x</span><span class="p">)</span> <span class="o">+</span> <span class="n">b</span>
    <span class="k">if</span> <span class="n">tmp</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">return</span> <span class="mi">0</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="mi">1</span>

<span class="k">if</span> <span class="n">__name__</span> <span class="o">==</span> <span class="s">'__main__'</span><span class="p">:</span>
    <span class="k">for</span> <span class="n">xs</span> <span class="ow">in</span> <span class="p">[(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)]:</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">AND</span><span class="p">(</span><span class="n">xs</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">xs</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
        <span class="k">print</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">xs</span><span class="p">)</span> <span class="o">+</span> <span class="s">" -&gt; "</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">y</span><span class="p">))</span>
</pre></table></code></div></div><h3 id="implement-nand-và-or">Implement NAND và OR</h3><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
</pre><td class="rouge-code"><pre>
<span class="c1"># coding: utf-8
</span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>


<span class="k">def</span> <span class="nf">NAND</span><span class="p">(</span><span class="n">x1</span><span class="p">,</span> <span class="n">x2</span><span class="p">):</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">([</span><span class="n">x1</span><span class="p">,</span> <span class="n">x2</span><span class="p">])</span>
    <span class="n">w</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">([</span><span class="o">-</span><span class="mf">0.5</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.5</span><span class="p">])</span>
    <span class="n">b</span> <span class="o">=</span> <span class="mf">0.7</span>
    <span class="n">tmp</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nb">sum</span><span class="p">(</span><span class="n">w</span><span class="o">*</span><span class="n">x</span><span class="p">)</span> <span class="o">+</span> <span class="n">b</span>
    <span class="k">if</span> <span class="n">tmp</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">return</span> <span class="mi">0</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="mi">1</span>

<span class="k">def</span> <span class="nf">OR</span><span class="p">(</span><span class="n">x1</span><span class="p">,</span> <span class="n">x2</span><span class="p">):</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">([</span><span class="n">x1</span><span class="p">,</span> <span class="n">x2</span><span class="p">])</span>
    <span class="n">w</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">])</span>
    <span class="n">b</span> <span class="o">=</span> <span class="o">-</span><span class="mf">0.2</span>
    <span class="n">tmp</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nb">sum</span><span class="p">(</span><span class="n">w</span><span class="o">*</span><span class="n">x</span><span class="p">)</span> <span class="o">+</span> <span class="n">b</span>
    <span class="k">if</span> <span class="n">tmp</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">return</span> <span class="mi">0</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="mi">1</span>

</pre></table></code></div></div><h2 id="perceptron-nhiều-tầng">Perceptron nhiều tầng</h2><p>Perceptron có thể biểu diễn được mạch AND, NAND, OR nhưng lại không thể biểu diễn được mạch XOR. Không tin bạn thử làm xem :)). Thực ra sự bá đạo của Perceptron là có thể chồng được nhiều tầng lên nhau. Với việc xếp chồng nhiều tầng, Perceptron sẽ biểu diễn được mạch XOR.</p><h3 id="kết-hợp-các-mạch-có-sẵn">Kết hợp các mạch có sẵn</h3><p>Mạch XOR:</p><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="/assets/img/posts/2018/04/-xor-gate.png" alt="-xor-gate" /></p><p>Tạo mạch XOR có nhiều cách nhưng cách đơn giản nhất là kết hợp từ các mạch AND, NAND, OR có sẵn.</p><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
</pre><td class="rouge-code"><pre><span class="k">def</span> <span class="nf">XOR</span><span class="p">(</span><span class="n">x1</span><span class="p">,</span><span class="n">x2</span><span class="p">):</span>
    <span class="n">gate1</span> <span class="o">=</span> <span class="n">NAND</span><span class="p">(</span><span class="n">x1</span><span class="p">,</span><span class="n">x2</span><span class="p">)</span>
    <span class="n">gate2</span> <span class="o">=</span> <span class="n">OR</span><span class="p">(</span><span class="n">x1</span><span class="p">,</span><span class="n">x2</span><span class="p">)</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">AND</span><span class="p">(</span><span class="n">gate1</span><span class="p">,</span> <span class="n">gate2</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">y</span>
</pre></table></code></div></div><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="/assets/img/posts/2018/04/XOR-Per.png" alt="XOR-Per" /></p><p>Lúc này sơ đồ luồng di chuyển sẽ như sau:</p><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="/content/images/2018/04/xor.png" alt="xor" /></p><p># Tổng kết Trên đây mình đã giới thiệu với các bạn Perceptron là gì. Ứng dụng nó ra sao. Đây là một thuật toán cực kỳ đơn giản nên chắc hẳn các bạn đã có thể hiểu được ngay. Bài viết sau mình sẽ giới thiệu về nền tảng của neural network. Và tất nhiên newral network sẽ được xây dựng dựa trên Perceptron nên hiểu nguyên lý hoạt động của Perceptron rất quan trọng.</p><p>Hẹn gặp lại các bạn ở bài viết sau.</p></div><div class="post-tail-wrapper text-muted"><div class="post-meta mb-3"> <i class="far fa-folder-open fa-fw mr-1"></i> <a href='/categories/blog/'>blog</a>, <a href='/categories/python/'>python</a></div><div class="post-tags"> <i class="fa fa-tags fa-fw mr-1"></i> <a href="/tags/blog/" class="post-tag no-text-decoration" >blog</a> <a href="/tags/python/" class="post-tag no-text-decoration" >python</a></div><div class="post-tail-bottom d-flex justify-content-between align-items-center mt-3 pt-5 pb-2"><div class="license-wrapper"> This post is licensed under <a href="https://creativecommons.org/licenses/by/4.0/">CC BY 4.0</a> by the author.</div><div class="share-wrapper"> <span class="share-label text-muted mr-1">Share</span> <span class="share-icons"> <a href="https://twitter.com/intent/tweet?text=Đi tìm cội nguồn của Deep Learning - Perceptron - thanhtt&url=https://codetudau.com/posts/deeplearning-perceptron-la-gi/" data-toggle="tooltip" data-placement="top" title="Twitter" target="_blank" rel="noopener" aria-label="Twitter"> <i class="fa-fw fab fa-twitter"></i> </a> <a href="https://www.facebook.com/sharer/sharer.php?title=Đi tìm cội nguồn của Deep Learning - Perceptron - thanhtt&u=https://codetudau.com/posts/deeplearning-perceptron-la-gi/" data-toggle="tooltip" data-placement="top" title="Facebook" target="_blank" rel="noopener" aria-label="Facebook"> <i class="fa-fw fab fa-facebook-square"></i> </a> <a href="https://telegram.me/share?text=Đi tìm cội nguồn của Deep Learning - Perceptron - thanhtt&url=https://codetudau.com/posts/deeplearning-perceptron-la-gi/" data-toggle="tooltip" data-placement="top" title="Telegram" target="_blank" rel="noopener" aria-label="Telegram"> <i class="fa-fw fab fa-telegram"></i> </a> <i class="fa-fw fas fa-link small" onclick="copyLink()" data-toggle="tooltip" data-placement="top" title="Copy link"></i> </span></div></div></div></div></div><div id="panel-wrapper" class="col-xl-3 pl-2 text-muted topbar-down"><div class="access"><div id="access-lastmod" class="post"> <span>Recent Update</span><ul class="post-content pl-0 pb-1 ml-1 mt-2"><li><a href="/posts/cai-thien-count-base/">Cải thiện phương pháp Count Base với Pointwise Mutual Information</a><li><a href="/posts/phan-tich-cay-quyet-dinh-scikit-learn/">Phân tích cây quyết định với scikit-learn</a></ul></div><div id="access-tags"> <span>Trending Tags</span><div class="d-flex flex-wrap mt-3 mb-1 mr-3"> <a class="post-tag" href="/tags/blog/">blog</a> <a class="post-tag" href="/tags/python/">python</a> <a class="post-tag" href="/tags/scikit-learn/">scikit-learn</a> <a class="post-tag" href="/tags/deep-learning/">deep-learning</a> <a class="post-tag" href="/tags/nlp/">NLP</a> <a class="post-tag" href="/tags/pandas/">pandas</a> <a class="post-tag" href="/tags/recommender-system/">recommender system</a> <a class="post-tag" href="/tags/spark/">spark</a></div></div></div><script src="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@1.0.1/dist/bootstrap-toc.min.js"></script><div id="toc-wrapper" class="pl-0 pr-4 mb-5"> <span class="pl-3 pt-2 mb-2">Contents</span><nav id="toc" data-toggle="toc"></nav></div></div></div><div class="row"><div class="col-12 col-lg-11 col-xl-8"><div id="post-extend-wrapper" class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-md-4 pr-md-4"><div id="widget-for-reem-15-1"></div><script src="https://reem.vn/reem.js?m=15"></script><div id="related-posts" class="mt-5 mb-2 mb-sm-4"><h3 class="pt-2 mt-1 mb-4 ml-1" data-toc-skip>Further Reading</h3><div class="card-deck mb-4"><div class="card"> <a href="/posts/bag-of-words-tf-idf-xu-ly-ngon-ngu-tu-nhien/"><div class="card-body"> <span class="timeago small" > Mar 9 <i class="unloaded">2021-03-09T07:33:00+07:00</i> </span><h3 class="pt-0 mt-1 mb-3" data-toc-skip>Bag of Words (Bow) TF-IDF - Xử lý ngôn ngữ tự nhiên</h3><div class="text-muted small"><p> Bag of Words là một thuật toán hỗ trợ xử lý ngôn ngữ tự nhiên và mục đích của BoW là phân loại text hay văn bản. Ý tưởng của BoW là phân tích và phân nhóm dựa theo “Bag of Words”(corpus). Với test ...</p></div></div></a></div><div class="card"> <a href="/posts/gioi-thieu-tien-xu-ly-trong-xu-ly-ngon-ngu-tu-nhien/"><div class="card-body"> <span class="timeago small" > Mar 9 <i class="unloaded">2021-03-09T08:33:00+07:00</i> </span><h3 class="pt-0 mt-1 mb-3" data-toc-skip>Giới thiệu tiền xử lý trong xử lý ngôn ngữ tự nhiên</h3><div class="text-muted small"><p> Mở đầu Chào các bạn, chắc hẳn ít nhiều các bạn đã từng nghe đến công việc xử lý ngôn ngữ tự nhiên. Nói một cách ngắn gọn như sau: Xử lý ngôn ngữ tự nhiên (natural language processing - NLP) là mộ...</p></div></div></a></div><div class="card"> <a href="/posts/machine-learning-nlp-scikit-learn/"><div class="card-body"> <span class="timeago small" > Mar 9 <i class="unloaded">2021-03-09T09:33:00+07:00</i> </span><h3 class="pt-0 mt-1 mb-3" data-toc-skip>Machine Learning NLP - Text Classification sử dụng scikit-learn</h3><div class="text-muted small"><p> Document/Text classification là 1 phần điển hình và quan trọng trong supervised machine learning. Phân loại các tài liệu(bài báo, tạp chí, trang web, hay là cả những status, comment trên MXH), nó c...</p></div></div></a></div></div></div><div class="post-navigation d-flex justify-content-between"> <a href="/posts/data-visualization-seaborn-python/" class="btn btn-outline-primary" prompt="Older"><p>Phải chăng matplotlib đã hết thời, Data Visualization bằng seaborn trên Python</p></a> <a href="/posts/neural-network-va-deep-learning-la-gi/" class="btn btn-outline-primary" prompt="Newer"><p>Neural Network và Deep Learning là gì ?</p></a></div></div></div></div><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/lozad/dist/lozad.min.js"></script> <script type="text/javascript"> const imgs = document.querySelectorAll('.post-content img'); const observer = lozad(imgs); observer.observe(); </script><footer class="d-flex w-100 justify-content-center"><div class="d-flex justify-content-between align-items-center"><div class="footer-left"><p class="mb-0"> © 2021 <a href="https://twitter.com/username">thanhtt</a>. <span data-toggle="tooltip" data-placement="top" title="Except where otherwise noted, the blog posts on this site are licensed under the Creative Commons Attribution 4.0 International (CC BY 4.0) License by the author."> Some rights reserved. </span></p></div><div class="footer-right"><p class="mb-0"> Powered by <a href="https://jekyllrb.com" target="_blank" rel="noopener">Jekyll</a> with <a href="https://github.com/cotes2020/jekyll-theme-chirpy" target="_blank" rel="noopener">Chirpy</a> theme.</p></div></div></footer></div><div id="search-result-wrapper" class="d-flex justify-content-center unloaded"><div class="col-12 col-sm-11 post-content"><div id="search-hints"><h4 class="text-muted mb-4">Trending Tags</h4><a class="post-tag" href="/tags/blog/">blog</a> <a class="post-tag" href="/tags/python/">python</a> <a class="post-tag" href="/tags/scikit-learn/">scikit learn</a> <a class="post-tag" href="/tags/deep-learning/">deep learning</a> <a class="post-tag" href="/tags/nlp/">NLP</a> <a class="post-tag" href="/tags/pandas/">pandas</a> <a class="post-tag" href="/tags/recommender-system/">recommender system</a> <a class="post-tag" href="/tags/spark/">spark</a></div><div id="search-results" class="d-flex flex-wrap justify-content-center text-muted mt-3"></div></div></div></div><script src="https://cdn.jsdelivr.net/npm/mermaid@8/dist/mermaid.min.js"></script> <script> $(function() { let initTheme = "default"; if ($("html[mode=dark]").length > 0 || ($("html[mode]").length == 0 && window.matchMedia("(prefers-color-scheme: dark)").matches ) ) { initTheme = "dark"; } let mermaidConf = { theme: initTheme /* <default|dark|forest|neutral> */ }; /* Markdown converts to HTML */ $("pre").has("code.language-mermaid").each(function() { let svgCode = $(this).children().html(); $(this).addClass("unloaded"); $(this).after(`<div class=\"mermaid\">${svgCode}</div>`); }); mermaid.initialize(mermaidConf); }); </script><div id="mask"></div><a id="back-to-top" href="#" aria-label="back-to-top" class="btn btn-lg btn-box-shadow" role="button"> <i class="fas fa-angle-up"></i> </a> <script src="https://cdn.jsdelivr.net/npm/simple-jekyll-search@1.7.3/dest/simple-jekyll-search.min.js"></script> <script> SimpleJekyllSearch({ searchInput: document.getElementById('search-input'), resultsContainer: document.getElementById('search-results'), json: '/assets/js/data/search.json', searchResultTemplate: '<div class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-lg-4 pr-lg-4 pl-xl-0 pr-xl-0"> <a href="https://codetudau.com{url}">{title}</a><div class="post-meta d-flex flex-column flex-sm-row text-muted mt-1 mb-1"> {categories} {tags}</div><p>{snippet}</p></div>', noResultsText: '<p class="mt-5">Oops! No result founds.</p>', templateMiddleware: function(prop, value, template) { if (prop === 'categories') { if (value === '') { return `${value}`; } else { return `<div class="mr-sm-4"><i class="far fa-folder fa-fw"></i>${value}</div>`; } } if (prop === 'tags') { if (value === '') { return `${value}`; } else { return `<div><i class="fa fa-tag fa-fw"></i>${value}</div>`; } } } }); </script>

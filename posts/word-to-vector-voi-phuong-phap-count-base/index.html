<!DOCTYPE html><html lang="vi" ><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><meta name="pv-cache-enabled" content="false"><meta name="generator" content="Jekyll v4.2.0" /><meta property="og:title" content="Word To Vector với phương pháp Count Base" /><meta name="author" content="thanhtt" /><meta property="og:locale" content="vi" /><meta name="description" content="Đi cùng với lịch sử phát triển của xử lý ngôn ngữ tự nhiên, đã có rất nhiều nghiên cứu về việc vector hoá từ. Nhìn vào các nghiên cứu đó có thể thấy hầu hết các phương pháp dựa trên một idea cơ bản đó chính là: Ý nghĩa của 1 từ được tạo thành từ các từ xung quanh." /><meta property="og:description" content="Đi cùng với lịch sử phát triển của xử lý ngôn ngữ tự nhiên, đã có rất nhiều nghiên cứu về việc vector hoá từ. Nhìn vào các nghiên cứu đó có thể thấy hầu hết các phương pháp dựa trên một idea cơ bản đó chính là: Ý nghĩa của 1 từ được tạo thành từ các từ xung quanh." /><link rel="canonical" href="https://codetudau.com/posts/word-to-vector-voi-phuong-phap-count-base/" /><meta property="og:url" content="https://codetudau.com/posts/word-to-vector-voi-phuong-phap-count-base/" /><meta property="og:site_name" content="thanhtt" /><meta property="og:type" content="article" /><meta property="article:published_time" content="2021-03-09T15:33:00+07:00" /><meta name="twitter:card" content="summary" /><meta property="twitter:title" content="Word To Vector với phương pháp Count Base" /><meta name="twitter:site" content="@twitter_username" /><meta name="twitter:creator" content="@thanhtt" /><meta name="google-site-verification" content="google_meta_tag_verification" /> <script type="application/ld+json"> {"headline":"Word To Vector với phương pháp Count Base","dateModified":"2021-03-09T15:33:00+07:00","datePublished":"2021-03-09T15:33:00+07:00","description":"Đi cùng với lịch sử phát triển của xử lý ngôn ngữ tự nhiên, đã có rất nhiều nghiên cứu về việc vector hoá từ. Nhìn vào các nghiên cứu đó có thể thấy hầu hết các phương pháp dựa trên một idea cơ bản đó chính là: Ý nghĩa của 1 từ được tạo thành từ các từ xung quanh.","url":"https://codetudau.com/posts/word-to-vector-voi-phuong-phap-count-base/","mainEntityOfPage":{"@type":"WebPage","@id":"https://codetudau.com/posts/word-to-vector-voi-phuong-phap-count-base/"},"@type":"BlogPosting","author":{"@type":"Person","name":"thanhtt"},"@context":"https://schema.org"}</script><title>Word To Vector với phương pháp Count Base | thanhtt</title><link rel="shortcut icon" href="/assets/img/favicons/favicon.ico" type="image/x-icon"><link rel="icon" href="/assets/img/favicons/favicon.ico" type="image/x-icon"><link rel="apple-touch-icon" href="/assets/img/favicons/apple-icon.png"><link rel="apple-touch-icon" href="/assets/img/favicons/apple-icon-precomposed.png"><link rel="apple-touch-icon" sizes="57x57" href="/assets/img/favicons/apple-icon-57x57.png"><link rel="apple-touch-icon" sizes="60x60" href="/assets/img/favicons/apple-icon-60x60.png"><link rel="apple-touch-icon" sizes="72x72" href="/assets/img/favicons/apple-icon-72x72.png"><link rel="apple-touch-icon" sizes="76x76" href="/assets/img/favicons/apple-icon-76x76.png"><link rel="apple-touch-icon" sizes="114x114" href="/assets/img/favicons/apple-icon-114x114.png"><link rel="apple-touch-icon" sizes="120x120" href="/assets/img/favicons/apple-icon-120x120.png"><link rel="apple-touch-icon" sizes="144x144" href="/assets/img/favicons/apple-icon-144x144.png"><link rel="apple-touch-icon" sizes="152x152" href="/assets/img/favicons/apple-icon-152x152.png"><link rel="apple-touch-icon" sizes="180x180" href="/assets/img/favicons/apple-icon-180x180.png"><link rel="icon" type="image/png" sizes="192x192" href="/assets/img/favicons/android-icon-192x192.png"><link rel="icon" type="image/png" sizes="32x32" href="/assets/img/favicons/favicon-32x32.png"><link rel="icon" type="image/png" sizes="96x96" href="/assets/img/favicons/favicon-96x96.png"><link rel="icon" type="image/png" sizes="16x16" href="/assets/img/favicons/favicon-16x16.png"><link rel="manifest" href="/assets/img/favicons/manifest.json"><meta name='msapplication-config' content='/assets/img/favicons/browserconfig.xml'><meta name="msapplication-TileColor" content="#ffffff"><meta name="msapplication-TileImage" content="/assets/img/favicons/ms-icon-144x144.png"><meta name="theme-color" content="#ffffff"><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin="anonymous"><link rel="dns-prefetch" href="https://fonts.gstatic.com"><link rel="preconnect" href="https://www.google-analytics.com" crossorigin="use-credentials"><link rel="dns-prefetch" href="https://www.google-analytics.com"><link rel="preconnect" href="https://www.googletagmanager.com" crossorigin="anonymous"><link rel="dns-prefetch" href="https://www.googletagmanager.com"><link rel="preconnect" href="cdn.jsdelivr.net"><link rel="dns-prefetch" href="cdn.jsdelivr.net"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.0.0/dist/css/bootstrap.min.css" integrity="sha256-LA89z+k9fjgMKQ/kq4OO2Mrf8VltYml/VES+Rg0fh20=" crossorigin="anonymous"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.11.2/css/all.min.css" integrity="sha256-+N4/V/SbAFiW1MPBCXnfnP9QSN3+Keu+NlB+0ev/YKQ=" crossorigin="anonymous"><link rel="stylesheet" href="/assets/css/style.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@1.0.1/dist/bootstrap-toc.min.css"> <script src="https://cdn.jsdelivr.net/npm/jquery@3/dist/jquery.min.js"></script> <script defer src="https://cdn.jsdelivr.net/combine/npm/popper.js@1.15.0,npm/bootstrap@4/dist/js/bootstrap.min.js"></script> <script defer src="/assets/js/dist/post.min.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script defer src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script> <script defer src="/app.js"></script> <script defer src="https://www.googletagmanager.com/gtag/js?id="></script> <script> document.addEventListener("DOMContentLoaded", function(event) { window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', ''); }); </script><body data-spy="scroll" data-target="#toc"><div id="sidebar" class="d-flex flex-column align-items-end"><div class="profile-wrapper text-center"><div id="avatar"> <a href="/" alt="avatar" class="mx-auto"> <img src="/assets/img/avatar/ttt-avatar.png" alt="avatar" onerror="this.style.display='none'"> </a></div><div class="site-title mt-3"> <a href="/">thanhtt</a></div><div class="site-subtitle font-italic">thanhtt - Data Engineer</div></div><ul class="w-100"><li class="nav-item"> <a href="/" class="nav-link"> <i class="fa-fw fas fa-home ml-xl-3 mr-xl-3 unloaded"></i> <span>HOME</span> </a><li class="nav-item"> <a href="/categories/" class="nav-link"> <i class="fa-fw fas fa-stream ml-xl-3 mr-xl-3 unloaded"></i> <span>CATEGORIES</span> </a><li class="nav-item"> <a href="/tags/" class="nav-link"> <i class="fa-fw fas fa-tags ml-xl-3 mr-xl-3 unloaded"></i> <span>TAGS</span> </a><li class="nav-item"> <a href="/archives/" class="nav-link"> <i class="fa-fw fas fa-archive ml-xl-3 mr-xl-3 unloaded"></i> <span>ARCHIVES</span> </a><li class="nav-item"> <a href="/about/" class="nav-link"> <i class="fa-fw fas fa-info ml-xl-3 mr-xl-3 unloaded"></i> <span>ABOUT</span> </a></ul><div class="sidebar-bottom mt-auto d-flex flex-wrap justify-content-center"> <a href="https://github.com/thanhttvn" aria-label="github" class="order-3" target="_blank" rel="noopener"> <i class="fab fa-github-alt"></i> </a> <a href="https://twitter.com/twitter_username" aria-label="twitter" class="order-4" target="_blank" rel="noopener"> <i class="fab fa-twitter"></i> </a> <a href=" javascript:location.href = 'mailto:' + ['thanhtt.vn93','gmail.com'].join('@')" aria-label="email" class="order-5" > <i class="fas fa-envelope"></i> </a> <a href="/feed.xml" aria-label="rss" class="order-6" > <i class="fas fa-rss"></i> </a> <span class="icon-border order-2"></span> <span id="mode-toggle-wrapper" class="order-1"> <i class="mode-toggle fas fa-adjust"></i> <script type="text/javascript"> class ModeToggle { static get MODE_KEY() { return "mode"; } static get DARK_MODE() { return "dark"; } static get LIGHT_MODE() { return "light"; } constructor() { if (this.hasMode) { if (this.isDarkMode) { if (!this.isSysDarkPrefer) { this.setDark(); } } else { if (this.isSysDarkPrefer) { this.setLight(); } } } var self = this; /* always follow the system prefers */ this.sysDarkPrefers.addListener(function() { if (self.hasMode) { if (self.isDarkMode) { if (!self.isSysDarkPrefer) { self.setDark(); } } else { if (self.isSysDarkPrefer) { self.setLight(); } } self.clearMode(); } self.updateMermaid(); }); } /* constructor() */ setDark() { $('html').attr(ModeToggle.MODE_KEY, ModeToggle.DARK_MODE); sessionStorage.setItem(ModeToggle.MODE_KEY, ModeToggle.DARK_MODE); } setLight() { $('html').attr(ModeToggle.MODE_KEY, ModeToggle.LIGHT_MODE); sessionStorage.setItem(ModeToggle.MODE_KEY, ModeToggle.LIGHT_MODE); } clearMode() { $('html').removeAttr(ModeToggle.MODE_KEY); sessionStorage.removeItem(ModeToggle.MODE_KEY); } get sysDarkPrefers() { return window.matchMedia("(prefers-color-scheme: dark)"); } get isSysDarkPrefer() { return this.sysDarkPrefers.matches; } get isDarkMode() { return this.mode == ModeToggle.DARK_MODE; } get isLightMode() { return this.mode == ModeToggle.LIGHT_MODE; } get hasMode() { return this.mode != null; } get mode() { return sessionStorage.getItem(ModeToggle.MODE_KEY); } /* get the current mode on screen */ get modeStatus() { if (this.isDarkMode || (!this.hasMode && this.isSysDarkPrefer) ) { return ModeToggle.DARK_MODE; } else { return ModeToggle.LIGHT_MODE; } } updateMermaid() { if (typeof mermaid !== "undefined") { let expectedTheme = (this.modeStatus === ModeToggle.DARK_MODE? "dark" : "default"); let config = { theme: expectedTheme }; /* re-render the SVG › <https://github.com/mermaid-js/mermaid/issues/311#issuecomment-332557344> */ $(".mermaid").each(function() { let svgCode = $(this).prev().children().html(); $(this).removeAttr("data-processed"); $(this).html(svgCode); }); mermaid.initialize(config); mermaid.init(undefined, ".mermaid"); } } flipMode() { if (this.hasMode) { if (this.isSysDarkPrefer) { if (this.isLightMode) { this.clearMode(); } else { this.setLight(); } } else { if (this.isDarkMode) { this.clearMode(); } else { this.setDark(); } } } else { if (this.isSysDarkPrefer) { this.setLight(); } else { this.setDark(); } } this.updateMermaid(); } /* flipMode() */ } /* ModeToggle */ let toggle = new ModeToggle(); $(".mode-toggle").click(function() { toggle.flipMode(); }); </script> </span></div></div><div id="topbar-wrapper" class="row justify-content-center topbar-down"><div id="topbar" class="col-11 d-flex h-100 align-items-center justify-content-between"> <span id="breadcrumb"> <span> <a href="/"> Posts </a> </span> <span>Word To Vector với phương pháp Count Base</span> </span> <i id="sidebar-trigger" class="fas fa-bars fa-fw"></i><div id="topbar-title"> Post</div><i id="search-trigger" class="fas fa-search fa-fw"></i> <span id="search-wrapper" class="align-items-center"> <i class="fas fa-search fa-fw"></i> <input class="form-control" id="search-input" type="search" aria-label="search" placeholder="Search..."> <i class="fa fa-times-circle fa-fw" id="search-cleaner"></i> </span> <span id="search-cancel" >Cancel</span></div></div><div id="main-wrapper"><div id="main"><div class="row"><div id="post-wrapper" class="col-12 col-lg-11 col-xl-8"><div class="post pl-1 pr-1 pl-sm-2 pr-sm-2 pl-md-4 pr-md-4"><h1 data-toc-skip>Word To Vector với phương pháp Count Base</h1><div class="post-meta text-muted d-flex flex-column"><div> <span class="semi-bold"> thanhtt </span> <span class="timeago " data-toggle="tooltip" data-placement="bottom" title="Tue, Mar 9, 2021, 3:33 PM +0700" prep="on" > Mar 9 <i class="unloaded">2021-03-09T15:33:00+07:00</i> </span></div><div> <span class="readtime" data-toggle="tooltip" data-placement="bottom" title="1632 words">9 min</span></div></div><div class="post-content"> <img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="/assets/img/posts/2019/01/count-base.png" class="preview-img" alt="Preview Image"><p>Đi cùng với lịch sử phát triển của xử lý ngôn ngữ tự nhiên, đã có rất nhiều nghiên cứu về việc vector hoá từ. Nhìn vào các nghiên cứu đó có thể thấy hầu hết các phương pháp dựa trên một idea cơ bản đó chính là:</p><blockquote><p>Ý nghĩa của 1 từ được tạo thành từ các từ xung quanh.</p></blockquote><p>Giới khoa học gọi ngắn gọn là <strong>distributional hypothesis</strong>, và dựa vào idea này, rất nhiều nghiên cứu về việc vector hoá từ được diễn ra. Thực chất bản chất của 1 từ không có ý nghĩa, mà tuỳ thuộc vào bối cảnh, đoạn văn đang nói tới mà mới mang ý nghĩa.</p><p>Ví dụ:</p><ul><li>I drink beer.<li>We drink wine.</ul><p>Có thể dễ dàng nhận thấy gần với 「<strong>drink</strong>」 là đồ uống. Và xét tiếp ví dụ sau:</p><ul><li>I guzzle beer.<li>We guzzle wine.</ul><p>Ồ có thể nhận ra được từ 「<strong>drink</strong>」 và 「<strong>guzzle</strong>」 được sử dụng trong cùng ngữ cảnh giống nhau, hơn nữa khả năng cao 「<strong>drink</strong>」 và 「<strong>guzzle</strong>」 có nghĩa giống nhau. Vậy từ đây phương pháp nào ra đời ?</p><h2 id="phương-pháp-countbase">Phương pháp CountBase</h2><p>Phần đầu mình có nhắc đến <strong>context(bối cảnh)</strong>, context được nhắc đến ở đây có nghĩa là những từ lân cận với từ đang cần vector hoá.</p><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="/assets/img/posts/2019/01/count-base-context.png" alt="count-base-context" /></p><p>Như ví dụ trên giả sử window size là 2, từ đang cần vector hoá là 「<strong>goodbye</strong>」 thì có 2 từ liền kề bên phải và trái được coi là context. Độ lớn của context chính là window size. Tương tự window size bằng 1 tức là phía bên phải và trái 1 từ. <sub>(*)Một số tài liệu lại sử dụng window size với ý nghĩa là size của một phía. Tuy nhiên đa số được hiểu như trên.</sub></p><p>Từ idea ban đầu có một phương pháp dễ dàng nghĩ tới là sẽ tiến hành count những từ xung quanh. Cụ thể là tương ứng với window size sẽ count những từ thuộc context. Chính vì vậy phương pháp này được coi là một Count Base Method. Cũng tuỳ tài liệu mà được gọi là Statistical Method.</p><p>Tiếp theo mình sẽ vừa code vừa giới thiệu chi tiết phương pháp này. Đầu tiên là chuẩn bị dữ liệu.</p><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
</pre><td class="rouge-code"><pre><span class="c1"># coding: utf-8
</span><span class="kn">import</span> <span class="nn">sys</span>
<span class="n">sys</span><span class="p">.</span><span class="n">path</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="s">'..'</span><span class="p">)</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>


<span class="k">def</span> <span class="nf">preprocess</span><span class="p">(</span><span class="n">text</span><span class="p">):</span>
    <span class="n">text</span> <span class="o">=</span> <span class="n">text</span><span class="p">.</span><span class="n">lower</span><span class="p">()</span>
    <span class="n">text</span> <span class="o">=</span> <span class="n">text</span><span class="p">.</span><span class="n">replace</span><span class="p">(</span><span class="s">'.'</span><span class="p">,</span> <span class="s">' .'</span><span class="p">)</span>
    <span class="n">words</span> <span class="o">=</span> <span class="n">text</span><span class="p">.</span><span class="n">split</span><span class="p">(</span><span class="s">' '</span><span class="p">)</span>
    <span class="n">word_to_id</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="n">id_to_word</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">words</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">word</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">word_to_id</span><span class="p">:</span>
            <span class="n">new_id</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">word_to_id</span><span class="p">)</span>
            <span class="n">word_to_id</span><span class="p">[</span><span class="n">word</span><span class="p">]</span> <span class="o">=</span> <span class="n">new_id</span>
            <span class="n">id_to_word</span><span class="p">[</span><span class="n">new_id</span><span class="p">]</span> <span class="o">=</span> <span class="n">word</span>
    <span class="n">corpus</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">([</span><span class="n">word_to_id</span><span class="p">[</span><span class="n">w</span><span class="p">]</span> <span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="n">words</span><span class="p">])</span>
    <span class="k">return</span> <span class="n">corpus</span><span class="p">,</span> <span class="n">word_to_id</span><span class="p">,</span> <span class="n">id_to_word</span>

<span class="n">text</span> <span class="o">=</span> <span class="s">'You say goodbye and I say hello.'</span>
<span class="n">corpus</span><span class="p">,</span> <span class="n">word_to_id</span><span class="p">,</span> <span class="n">id_to_word</span> <span class="o">=</span> <span class="n">preprocess</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="n">corpus</span><span class="p">)</span>
<span class="c1">#[0 1 2 3 4 1 5 6]
</span><span class="k">print</span><span class="p">(</span><span class="n">id_to_word</span><span class="p">)</span>
<span class="c1">#{0: 'you', 1: 'say', 2: 'goodbye', 3: 'and', 4: 'i', 5: 'hello', 6: '.'}
</span></pre></table></code></div></div><p>Dễ dàng thấy được tổng số từ là 7. Tiếp theo set window size bằng 1 và đếm những từ thuộc context.</p><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="/assets/img/posts/2019/01/count-base-2.png" alt="count-base-2" /></p><p>Với window size bằng 1 thì bối cảnh từ 「<strong>you</strong>」 chỉ có duy nhất từ 「<strong>say</strong>」. Vậy từ 「<strong>say</strong>」 mang giá trị 1, còn các từ khác 0.</p><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="/assets/img/posts/2019/01/count-base-3.png" alt="count-base-3" /></p><p>Tương tự từ tiếp theo là từ 「<strong>say</strong>」. Sẽ được kết quả như sau:</p><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="/assets/img/posts/2019/01/count-base-4.png" alt="count-base-4" /></p><p>OK, vậy là từ 「<strong>say</strong>」 có thể biểu diễn bằng vector [1, 0, 1, 0, 1, 1, 0]. Và làm tương tự với các từ còn lại.</p><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="/assets/img/posts/2019/01/count-base-5.png" alt="count-base-5" /></p><p>Hình trên chính là một ma trận được gọi là <strong>co-occurence matrix</strong>. Vậy code như thế nào để ra kết quả như trên, thực tế lượng corpus rất lớn nên không thể dùng cơm để tạo ma trận được rồi. :D</p><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
</pre><td class="rouge-code"><pre><span class="k">def</span> <span class="nf">create_co_matrix</span><span class="p">(</span><span class="n">corpus</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">,</span> <span class="n">window_size</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
    <span class="s">'''create co-occurence matrix
    :param corpus: danh sách word id
    :param vocab_size:số từ
    :param window_size: window size
    :return: co-occurence matrix
    '''</span>
    <span class="n">corpus_size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">corpus</span><span class="p">)</span>
    <span class="n">co_matrix</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">vocab_size</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="p">.</span><span class="n">int32</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">word_id</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">corpus</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">window_size</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>
            <span class="n">left_idx</span> <span class="o">=</span> <span class="n">idx</span> <span class="o">-</span> <span class="n">i</span>
            <span class="n">right_idx</span> <span class="o">=</span> <span class="n">idx</span> <span class="o">+</span> <span class="n">i</span>
            <span class="k">if</span> <span class="n">left_idx</span> <span class="o">&gt;=</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">left_word_id</span> <span class="o">=</span> <span class="n">corpus</span><span class="p">[</span><span class="n">left_idx</span><span class="p">]</span>
                <span class="n">co_matrix</span><span class="p">[</span><span class="n">word_id</span><span class="p">,</span> <span class="n">left_word_id</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">1</span>
            <span class="k">if</span> <span class="n">right_idx</span> <span class="o">&lt;</span> <span class="n">corpus_size</span><span class="p">:</span>
                <span class="n">right_word_id</span> <span class="o">=</span> <span class="n">corpus</span><span class="p">[</span><span class="n">right_idx</span><span class="p">]</span>
                <span class="n">co_matrix</span><span class="p">[</span><span class="n">word_id</span><span class="p">,</span> <span class="n">right_word_id</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">1</span>
    <span class="k">return</span> <span class="n">co_matrix</span>

<span class="n">create_co_matrix</span><span class="p">(</span><span class="n">corpus</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="n">window_size</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="c1"># array([[0, 1, 0, 0, 0, 0, 0],
</span>       <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>
       <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>
       <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>
       <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>
       <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>
       <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">]],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">int32</span><span class="p">)</span>
</pre></table></code></div></div><h1 id="mức-độ-tương-đồng-của-2-vector">Mức độ tương đồng của 2 vector</h1><p>OK, phần trước chúng ta đã có thể tạo được ma trận Co-occurence. Tức là đã có vector của từng từ rồi, việc còn lại cũng rất quan trọng trong NLP đó là tính mức độ tương đồng của các vector. Tại sao nó lại mang ý nghĩa quan trọng ? Thực tế có thể thấy 1 từ sẽ có các từ khác đồng nghĩa, chính vì vậy xác định được các từ đồng nghĩa cũng hết sức quan trọng. Và độ tương đồng của 2 vector từ càng lớn thì 2 từ đó càng mang ý nghĩa giống nhau.</p><p>Và nói đến phương pháp thì cũng có thể nghĩ đến rất nhiều phương pháp như tính tích vô hướng của 2 vector, hay tính khoản cách eculid… Tuy nhiên liên quan đến việc tính độ tương đồng của vector từ thì <strong>cosine similarity</strong> được sử dụng rất nhiều. Định nghĩa đối với 2 vector \(x = \big(x_{1}, x_{2}, x_{3},..., x_{n}\big)\) và \(y = \big(y_{1}, y_{2}, y_{3},..., y_{n}\big)\)</p>\[similarity \big(x, y \big) = \frac{x * y}{ \parallel x \parallel \parallel y \parallel } = \frac{ x_{1}y_{1} + ... + x_{n}y_{n}}{ \sqrt{ x_{1}^{2} + ... + x_{n}^{2} } \sqrt{ y_{1}^{2} + ... + y_{n}^{2} } }\]<p>Phần tử là <strong>tích vô hướng</strong> 2 vector, phần mẫu là <strong>norm L2</strong> của từng vector. Điểm cần chú ý ở công thức trên là việc lấy tích vô hướng sau khi regularize.</p><blockquote><p>Norm là cách tính biểu thị độ lớn của vector.</p></blockquote><p>Nhìn một cách trực quan thì <strong>cosine similarity</strong> cho biết hướng của 2 vector như thế nào. 2 vector hoàn toàn cùng hướng với nhau thì cosine similarity = 1, hoàn toàn ngược hướng thì cosine similarity = -1.</p><p>Code của công thức trên đơn giản như sau:</p><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
</pre><td class="rouge-code"><pre><span class="k">def</span> <span class="nf">cos_similarity</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="mf">1e-8</span><span class="p">):</span>
    <span class="s">'''Tính cosine similarity
    :param x: vector
    :param y: vector
    :param eps: Tránh trường hợp chia cho 0 khi vector 0
    :return:
    '''</span>
    <span class="n">nx</span> <span class="o">=</span> <span class="n">x</span> <span class="o">/</span> <span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nb">sum</span><span class="p">(</span><span class="n">x</span> <span class="o">**</span> <span class="mi">2</span><span class="p">))</span> <span class="o">+</span> <span class="n">eps</span><span class="p">)</span> <span class="c1"># regularize vector x
</span>    <span class="n">ny</span> <span class="o">=</span> <span class="n">y</span> <span class="o">/</span> <span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nb">sum</span><span class="p">(</span><span class="n">y</span> <span class="o">**</span> <span class="mi">2</span><span class="p">))</span> <span class="o">+</span> <span class="n">eps</span><span class="p">)</span> <span class="c1"># regularize vector y
</span>    <span class="k">return</span> <span class="n">np</span><span class="p">.</span><span class="n">dot</span><span class="p">(</span><span class="n">nx</span><span class="p">,</span> <span class="n">ny</span><span class="p">)</span>
</pre></table></code></div></div><p>OK, vậy là chúng ta đã tính được độ tương đồng của 2 vector, tiếp tục với ví dụ trên thử tính cosine similarity của từ 「 <strong>i</strong>」và「<strong>you</strong>」xem sao?</p><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
</pre><td class="rouge-code"><pre>
<span class="n">c0</span> <span class="o">=</span> <span class="n">C</span><span class="p">[</span><span class="n">word_to_id</span><span class="p">[</span><span class="s">'you'</span><span class="p">]]</span>  <span class="c1"># vector của「you」
</span><span class="n">c1</span> <span class="o">=</span> <span class="n">C</span><span class="p">[</span><span class="n">word_to_id</span><span class="p">[</span><span class="s">'i'</span><span class="p">]]</span>  <span class="c1">#vector của「i」
</span><span class="k">print</span><span class="p">(</span><span class="n">cos_similarity</span><span class="p">(</span><span class="n">c0</span><span class="p">,</span> <span class="n">c1</span><span class="p">))</span>

<span class="c1">#0.7071067691154799
</span></pre></table></code></div></div><h1 id="tìm-từ-đồng-nghĩa">Tìm từ đồng nghĩa</h1><p>Từ việc tính được cosine similarity như trên, không phải là quá dễ dàng để tìm được những từ đồng nghĩa hay sao. Tuy nhiên chính từ ví dụ này, cũng có thể nhận thấy phương pháp <strong>Count Base</strong> có khuyết điểm.</p><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
</pre><td class="rouge-code"><pre>
<span class="k">def</span> <span class="nf">most_similar</span><span class="p">(</span><span class="n">query</span><span class="p">,</span> <span class="n">word_to_id</span><span class="p">,</span> <span class="n">id_to_word</span><span class="p">,</span> <span class="n">word_matrix</span><span class="p">,</span> <span class="n">top</span><span class="o">=</span><span class="mi">5</span><span class="p">):</span>
    <span class="s">'''Tìm từ đồng nghĩa
    :param query: từ cần tìm
    :param word_to_id: dict để word to id
    :param id_to_word: dict để từ id to word
    :param word_matrix: co-occurence matrix
    :param top: lấy top bao nhiêu
    '''</span>
    <span class="k">if</span> <span class="n">query</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">word_to_id</span><span class="p">:</span>
        <span class="k">print</span><span class="p">(</span><span class="s">'%s is not found'</span> <span class="o">%</span> <span class="n">query</span><span class="p">)</span>
        <span class="k">return</span>
    <span class="k">print</span><span class="p">(</span><span class="s">'</span><span class="se">\n</span><span class="s">[query] '</span> <span class="o">+</span> <span class="n">query</span><span class="p">)</span>
    <span class="n">query_id</span> <span class="o">=</span> <span class="n">word_to_id</span><span class="p">[</span><span class="n">query</span><span class="p">]</span>
    <span class="n">query_vec</span> <span class="o">=</span> <span class="n">word_matrix</span><span class="p">[</span><span class="n">query_id</span><span class="p">]</span>
    <span class="n">vocab_size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">id_to_word</span><span class="p">)</span>
    <span class="n">similarity</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">vocab_size</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">vocab_size</span><span class="p">):</span>
        <span class="n">similarity</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">cos_similarity</span><span class="p">(</span><span class="n">word_matrix</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">query_vec</span><span class="p">)</span>
    <span class="n">count</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="p">(</span><span class="o">-</span><span class="mi">1</span> <span class="o">*</span> <span class="n">similarity</span><span class="p">).</span><span class="n">argsort</span><span class="p">():</span>
        <span class="k">if</span> <span class="n">id_to_word</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">==</span> <span class="n">query</span><span class="p">:</span>
            <span class="k">continue</span>
        <span class="k">print</span><span class="p">(</span><span class="s">' %s: %s'</span> <span class="o">%</span> <span class="p">(</span><span class="n">id_to_word</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">similarity</span><span class="p">[</span><span class="n">i</span><span class="p">]))</span>
        <span class="n">count</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="k">if</span> <span class="n">count</span> <span class="o">&gt;=</span> <span class="n">top</span><span class="p">:</span>
            <span class="k">return</span>

<span class="n">most_similar</span><span class="p">(</span><span class="s">"you"</span><span class="p">,</span> <span class="n">word_to_id</span><span class="p">,</span> <span class="n">id_to_word</span><span class="p">,</span> <span class="n">C</span><span class="p">)</span>

<span class="c1">#[query] you
# goodbye: 0.7071067691154799
# i: 0.7071067691154799
# hello: 0.7071067691154799
# say: 0.0
# and: 0.0
</span></pre></table></code></div></div><p>Nhìn từ kết quả có thể nhận thấy giống nhất từ 「 <strong>you</strong>」có 3 từ:「<strong>goodbye</strong>」,「<strong>i</strong>」, 「<strong>hello</strong>」. 「 <strong>you</strong>」 và 「<strong>i</strong>」đúng là 2 danh từ chỉ người, cũng mang nghĩa khá tương đồng → ok đúng. 「 <strong>you</strong>」với 「<strong>goodbye</strong>」và 「<strong>hello</strong>」mà có giá trị cosine similarity lớn thì đúng là sai thật. Đương nhiên là với lượng corpus quá ít như này cũng là 1 nguyên nhân. Bạn hãy thử với lượng corpus nhiều hơn xem kết quả có được như mong đợi không nhé. Ngoài ra nhìn vào <strong>co-occurence matrix</strong> có thể nhận thấy ma trận có số chiều rất lớn. Nếu lượng data nhiều thì xử lý sẽ rất chậm. Và đương nhiên cũng sẽ có cách cải thiện vấn đề này.</p><h1 id="lời-kết">Lời kết</h1><p>Phạm vi bài viết này chỉ mới nói đến kiến thức cơ bản nhất của phương pháp <strong>Count Base</strong>, kiến thức cơ bản này mình đọc từ cuốn sách (link phía dưới) thấy hay nên đã viết lại chi tiết nhất để ai cũng có thể hiểu được và ứng dụng ngay. Và đương nhiên bài viết này không dừng lại tại đây, những bài viết tiếp theo mình sẽ nói đến các phương pháp cải tiến phương pháp này để hiệu quả hơn nữa.</p><h1 id="tài-liệu">Tài liệu</h1><p>https://www.oreilly.co.jp/books/9784873118369/</p></div><div class="post-tail-wrapper text-muted"><div class="post-meta mb-3"> <i class="far fa-folder-open fa-fw mr-1"></i> <a href='/categories/blog/'>blog</a>, <a href='/categories/python/'>python</a>, <a href='/categories/deep-learning/'>deep-learning</a></div><div class="post-tags"> <i class="fa fa-tags fa-fw mr-1"></i> <a href="/tags/blog/" class="post-tag no-text-decoration" >blog</a> <a href="/tags/python/" class="post-tag no-text-decoration" >python</a> <a href="/tags/deep-learning/" class="post-tag no-text-decoration" >deep-learning</a></div><div class="post-tail-bottom d-flex justify-content-between align-items-center mt-3 pt-5 pb-2"><div class="license-wrapper"> This post is licensed under <a href="https://creativecommons.org/licenses/by/4.0/">CC BY 4.0</a> by the author.</div><div class="share-wrapper"> <span class="share-label text-muted mr-1">Share</span> <span class="share-icons"> <a href="https://twitter.com/intent/tweet?text=Word To Vector với phương pháp Count Base - thanhtt&url=https://codetudau.com/posts/word-to-vector-voi-phuong-phap-count-base/" data-toggle="tooltip" data-placement="top" title="Twitter" target="_blank" rel="noopener" aria-label="Twitter"> <i class="fa-fw fab fa-twitter"></i> </a> <a href="https://www.facebook.com/sharer/sharer.php?title=Word To Vector với phương pháp Count Base - thanhtt&u=https://codetudau.com/posts/word-to-vector-voi-phuong-phap-count-base/" data-toggle="tooltip" data-placement="top" title="Facebook" target="_blank" rel="noopener" aria-label="Facebook"> <i class="fa-fw fab fa-facebook-square"></i> </a> <a href="https://telegram.me/share?text=Word To Vector với phương pháp Count Base - thanhtt&url=https://codetudau.com/posts/word-to-vector-voi-phuong-phap-count-base/" data-toggle="tooltip" data-placement="top" title="Telegram" target="_blank" rel="noopener" aria-label="Telegram"> <i class="fa-fw fab fa-telegram"></i> </a> <i class="fa-fw fas fa-link small" onclick="copyLink()" data-toggle="tooltip" data-placement="top" title="Copy link"></i> </span></div></div></div></div></div><div id="panel-wrapper" class="col-xl-3 pl-2 text-muted topbar-down"><div class="access"><div id="access-lastmod" class="post"> <span>Recent Update</span><ul class="post-content pl-0 pb-1 ml-1 mt-2"><li><a href="/posts/cai-thien-count-base/">Cải thiện phương pháp Count Base với Pointwise Mutual Information</a><li><a href="/posts/phan-tich-cay-quyet-dinh-scikit-learn/">Phân tích cây quyết định với scikit-learn</a></ul></div><div id="access-tags"> <span>Trending Tags</span><div class="d-flex flex-wrap mt-3 mb-1 mr-3"> <a class="post-tag" href="/tags/blog/">blog</a> <a class="post-tag" href="/tags/python/">python</a> <a class="post-tag" href="/tags/scikit-learn/">scikit-learn</a> <a class="post-tag" href="/tags/deep-learning/">deep-learning</a> <a class="post-tag" href="/tags/nlp/">NLP</a> <a class="post-tag" href="/tags/pandas/">pandas</a> <a class="post-tag" href="/tags/recommender-system/">recommender system</a> <a class="post-tag" href="/tags/spark/">spark</a></div></div></div><script src="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@1.0.1/dist/bootstrap-toc.min.js"></script><div id="toc-wrapper" class="pl-0 pr-4 mb-5"> <span class="pl-3 pt-2 mb-2">Contents</span><nav id="toc" data-toggle="toc"></nav></div></div></div><div class="row"><div class="col-12 col-lg-11 col-xl-8"><div id="post-extend-wrapper" class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-md-4 pr-md-4"><div id="widget-for-reem-15-1"></div><script src="https://reem.vn/reem.js?m=15"></script><div id="related-posts" class="mt-5 mb-2 mb-sm-4"><h3 class="pt-2 mt-1 mb-4 ml-1" data-toc-skip>Further Reading</h3><div class="card-deck mb-4"><div class="card"> <a href="/posts/neural-network-va-deep-learning-la-gi/"><div class="card-body"> <span class="timeago small" > Mar 9 <i class="unloaded">2021-03-09T15:33:00+07:00</i> </span><h3 class="pt-0 mt-1 mb-3" data-toc-skip>Neural Network và Deep Learning là gì ?</h3><div class="text-muted small"><p> Chào các bạn, hôm nay đẹp trời lại có thời gian rảnh mình sẽ viết tiếp chuỗi bài về Deep Learning. Như bài trước mình đã giới thiệu với các bạn về Perceptron, nếu bạn chưa biết thì bạn có thể xem l...</p></div></div></a></div><div class="card"> <a href="/posts/bag-of-words-tf-idf-xu-ly-ngon-ngu-tu-nhien/"><div class="card-body"> <span class="timeago small" > Mar 9 <i class="unloaded">2021-03-09T07:33:00+07:00</i> </span><h3 class="pt-0 mt-1 mb-3" data-toc-skip>Bag of Words (Bow) TF-IDF - Xử lý ngôn ngữ tự nhiên</h3><div class="text-muted small"><p> Bag of Words là một thuật toán hỗ trợ xử lý ngôn ngữ tự nhiên và mục đích của BoW là phân loại text hay văn bản. Ý tưởng của BoW là phân tích và phân nhóm dựa theo “Bag of Words”(corpus). Với test ...</p></div></div></a></div><div class="card"> <a href="/posts/gioi-thieu-tien-xu-ly-trong-xu-ly-ngon-ngu-tu-nhien/"><div class="card-body"> <span class="timeago small" > Mar 9 <i class="unloaded">2021-03-09T08:33:00+07:00</i> </span><h3 class="pt-0 mt-1 mb-3" data-toc-skip>Giới thiệu tiền xử lý trong xử lý ngôn ngữ tự nhiên</h3><div class="text-muted small"><p> Mở đầu Chào các bạn, chắc hẳn ít nhiều các bạn đã từng nghe đến công việc xử lý ngôn ngữ tự nhiên. Nói một cách ngắn gọn như sau: Xử lý ngôn ngữ tự nhiên (natural language processing - NLP) là mộ...</p></div></div></a></div></div></div><div class="post-navigation d-flex justify-content-between"> <a href="/posts/neural-network-va-deep-learning-la-gi/" class="btn btn-outline-primary" prompt="Older"><p>Neural Network và Deep Learning là gì ?</p></a> <a href="/posts/cai-thien-count-base/" class="btn btn-outline-primary" prompt="Newer"><p>Cải thiện phương pháp Count Base với Pointwise Mutual Information</p></a></div></div></div></div><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/lozad/dist/lozad.min.js"></script> <script type="text/javascript"> const imgs = document.querySelectorAll('.post-content img'); const observer = lozad(imgs); observer.observe(); </script><footer class="d-flex w-100 justify-content-center"><div class="d-flex justify-content-between align-items-center"><div class="footer-left"><p class="mb-0"> © 2021 <a href="https://twitter.com/username">thanhtt</a>. <span data-toggle="tooltip" data-placement="top" title="Except where otherwise noted, the blog posts on this site are licensed under the Creative Commons Attribution 4.0 International (CC BY 4.0) License by the author."> Some rights reserved. </span></p></div><div class="footer-right"><p class="mb-0"> Powered by <a href="https://jekyllrb.com" target="_blank" rel="noopener">Jekyll</a> with <a href="https://github.com/cotes2020/jekyll-theme-chirpy" target="_blank" rel="noopener">Chirpy</a> theme.</p></div></div></footer></div><div id="search-result-wrapper" class="d-flex justify-content-center unloaded"><div class="col-12 col-sm-11 post-content"><div id="search-hints"><h4 class="text-muted mb-4">Trending Tags</h4><a class="post-tag" href="/tags/blog/">blog</a> <a class="post-tag" href="/tags/python/">python</a> <a class="post-tag" href="/tags/scikit-learn/">scikit learn</a> <a class="post-tag" href="/tags/deep-learning/">deep learning</a> <a class="post-tag" href="/tags/nlp/">NLP</a> <a class="post-tag" href="/tags/pandas/">pandas</a> <a class="post-tag" href="/tags/recommender-system/">recommender system</a> <a class="post-tag" href="/tags/spark/">spark</a></div><div id="search-results" class="d-flex flex-wrap justify-content-center text-muted mt-3"></div></div></div></div><script src="https://cdn.jsdelivr.net/npm/mermaid@8/dist/mermaid.min.js"></script> <script> $(function() { let initTheme = "default"; if ($("html[mode=dark]").length > 0 || ($("html[mode]").length == 0 && window.matchMedia("(prefers-color-scheme: dark)").matches ) ) { initTheme = "dark"; } let mermaidConf = { theme: initTheme /* <default|dark|forest|neutral> */ }; /* Markdown converts to HTML */ $("pre").has("code.language-mermaid").each(function() { let svgCode = $(this).children().html(); $(this).addClass("unloaded"); $(this).after(`<div class=\"mermaid\">${svgCode}</div>`); }); mermaid.initialize(mermaidConf); }); </script><div id="mask"></div><a id="back-to-top" href="#" aria-label="back-to-top" class="btn btn-lg btn-box-shadow" role="button"> <i class="fas fa-angle-up"></i> </a> <script src="https://cdn.jsdelivr.net/npm/simple-jekyll-search@1.7.3/dest/simple-jekyll-search.min.js"></script> <script> SimpleJekyllSearch({ searchInput: document.getElementById('search-input'), resultsContainer: document.getElementById('search-results'), json: '/assets/js/data/search.json', searchResultTemplate: '<div class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-lg-4 pr-lg-4 pl-xl-0 pr-xl-0"> <a href="https://codetudau.com{url}">{title}</a><div class="post-meta d-flex flex-column flex-sm-row text-muted mt-1 mb-1"> {categories} {tags}</div><p>{snippet}</p></div>', noResultsText: '<p class="mt-5">Oops! No result founds.</p>', templateMiddleware: function(prop, value, template) { if (prop === 'categories') { if (value === '') { return `${value}`; } else { return `<div class="mr-sm-4"><i class="far fa-folder fa-fw"></i>${value}</div>`; } } if (prop === 'tags') { if (value === '') { return `${value}`; } else { return `<div><i class="fa fa-tag fa-fw"></i>${value}</div>`; } } } }); </script>
